{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luizp/projects/pibit/pibit/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import random \n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1701\n",
    "EPOCHS = 20\n",
    "MODEL_REPO = \"/home/luizp/projects/pibit/src/cleaner/nslClean.csv\"\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToImage:\n",
    "    def __call__(self, array: torch.Tensor, keep_normalization=True):\n",
    "        \"\"\" The idea is to convert a 1d array to a 2d array by resizing (with padding) to the square root of the 1d shape\n",
    "\n",
    "        Ex: \n",
    "            - shape: 2048  \n",
    "            - sqrt(shape) = 45.25 -> round to ceil (46)\n",
    "            - resize the feature vector to 46x46 \n",
    "            - return the new feature vector as a RGB PIL Image for torchvision transforms\n",
    "         \"\"\"\n",
    "        #feat = array.shape[0]\n",
    "        feat = array.shape[0]\n",
    "        n = int(np.ceil(feat ** 0.5))\n",
    "\n",
    "        array = array.cpu().numpy().copy()\n",
    "        \n",
    "        # Squared size with padding\n",
    "        array.resize((n, n))\n",
    "        if not keep_normalization:\n",
    "            return (array * 255).astype(np.uint8)\n",
    "\n",
    "        return torch.Tensor(array.astype(np.float32)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\" Custom dataset class used for applying transforms to the features. \"\"\"\n",
    "    def __init__(self, subset: Tuple[torch.Tensor, torch.Tensor], transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[0][index], self.subset[1][index]\n",
    "    \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.subset[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(device: str, epoch: int, loss_fn, MODEL, dataset: DataLoader):\n",
    "    # Validation\n",
    "    MODEL.eval()\n",
    "    it_eval = tqdm(enumerate(dataset), total=len(dataset))\n",
    "    running_loss = 0.\n",
    "    correct = 0\n",
    "    qt = 1\n",
    "    metrics = dict(tp=0, tn=0, fp=0, fn=0)\n",
    "    y_pred = list()\n",
    "    y_true = list()\n",
    "    with torch.no_grad():\n",
    "        for _, (x, y) in it_eval:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = MODEL(x)\n",
    "            running_loss += loss_fn(output, y).item()\n",
    "            y_pred.extend(torch.argmax(output, 1).cpu().numpy())\n",
    "            y_true.extend(y.data.cpu().numpy())\n",
    "            correct += torch.sum(torch.argmax(output, 1).eq(y)).item()\n",
    "            qt += len(x)\n",
    "            desc = f\"[{now()}] Epoch {str(epoch).zfill(3)} Val. Acc: {correct/qt:.4f} Val. Loss: {running_loss / len(dataset):.8f}\"\n",
    "            it_eval.set_description(desc)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    metrics[\"tp\"] = tp\n",
    "    metrics[\"fp\"] = fp\n",
    "    metrics[\"tn\"] = tn\n",
    "    metrics[\"fn\"] = fn\n",
    "    return running_loss / len(dataset), correct/qt, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now():\n",
    "    return dt.now().strftime(\"%d-%m-%Y %H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device: str, epoch: int, optimizer, loss_fn, MODEL, dataset: DataLoader):\n",
    "    # Put the MODEL in the training mode\n",
    "    MODEL.train()\n",
    "    running_loss = 0.\n",
    "    qt = 1\n",
    "    correct = 0\n",
    "\n",
    "    # Just add a fancy progress bar to the terminal...\n",
    "    it = tqdm(enumerate(dataset), total=len(dataset))\n",
    "\n",
    "    for _, (x, y) in it:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Make predictions for this batch\n",
    "        outputs = MODEL(x)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        correct += torch.sum(torch.argmax(outputs, 1).eq(y)).item()\n",
    "        qt += len(x)\n",
    "    \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        desc = f\"[{now()}] Epoch {str(epoch).zfill(3)} Acc: {correct/qt:.4f} Loss: {running_loss / len(dataset):.8f}\"\n",
    "        it.set_description(desc)\n",
    "    \n",
    "    # Loss / Accuracy\n",
    "    return running_loss / len(dataset), correct/qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "  def __init__(self, num_classes=2):\n",
    "    super(AlexNet, self).__init__()\n",
    "    self.features = nn.Sequential(\n",
    "      nn.Conv2d(1, 128, kernel_size=7, stride=4, padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=1, stride=2),\n",
    "        nn.Conv2d(128, 128, kernel_size=1, padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        nn.Conv2d(128, 128, kernel_size=2, padding=1),\n",
    "        nn.ReLU(inplace=True),            \n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),            \n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    )\n",
    "        \n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(4608, 128),\n",
    "      nn.ReLU(inplace=True),            \n",
    "      nn.Dropout(),\n",
    "      nn.Linear(128, 128),\n",
    "      nn.ReLU(inplace=True),            \n",
    "      nn.Linear(128, num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_update():\n",
    "    # Reproducibility\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "\n",
    "    MODEL = AlexNet().to('cuda')\n",
    "\n",
    "    #if MODEL is None or not isinstance(nn.Module):\n",
    "    #    raise TypeError(\"The model does not exist or isn't an instance of nn.Module (PyTorch)\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        ToImage(),\n",
    "    ])\n",
    "    csv_path = \"/home/luizp/projects/pibit/src/cleaner/nslClean.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    y = df.iloc[:, -2].values\n",
    "    x = df.iloc[:, :-2].values\n",
    "    y = y[::-1]\n",
    "    x = np.squeeze(x)\n",
    "    #x = x.reshape((1, -1))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    #raise Exception(\"Precisa carregar e separar (treino, validação e teste) um dataset qualquer para executar\")\n",
    "    x_train = torch.Tensor(x_train)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    x_test  = torch.Tensor(x_test)\n",
    "    y_test  = torch.LongTensor(y_test)\n",
    "    #x_val   = torch.Tensor(x_val)\n",
    "    #y_val   = torch.LongTensor(y_val)\n",
    "\n",
    "    # A parte de fazer o reshape está quando passo uma transformada (ToImage()) como parâmetro\n",
    "    cd_train = CustomDataset(subset=(x_train, y_train), transform=transform)\n",
    "    cd_test  = CustomDataset(subset=(x_test, y_test), transform=transform)\n",
    "    #cd_val   = CustomDataset(subset=(X_val, y_val), transform=transform)\n",
    "\n",
    "    data_train = DataLoader(cd_train, shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "    data_test  = DataLoader(cd_test, shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "    #data_val   = DataLoader(cd_val, shuffle=True, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n",
    "    loss_fn   = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(MODEL.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss, train_acc = train(device, epoch, optimizer, loss_fn, MODEL, data_train)\n",
    "        #val_loss, val_acc, _ = validate(device, epoch, optimizer, loss_fn, MODEL, data_val)\n",
    "\n",
    "        _, _, metrics = validate(device, epoch, loss_fn, MODEL, data_test)\n",
    "        print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-09-48] Epoch 001 Acc: 0.5025 Loss: 0.69326344: 100%|██████████| 886/886 [00:20<00:00, 43.61it/s]\n",
      "[30-01-2024 22-09-49] Epoch 001 Val. Acc: 0.4988 Val. Loss: 0.69351727: 100%|██████████| 99/99 [00:01<00:00, 82.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 0, 'tn': 6285, 'fp': 0, 'fn': 6313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-10-09] Epoch 002 Acc: 0.5035 Loss: 0.69316063: 100%|██████████| 886/886 [00:20<00:00, 44.27it/s]\n",
      "[30-01-2024 22-10-11] Epoch 002 Val. Acc: 0.5011 Val. Loss: 0.69314661: 100%|██████████| 99/99 [00:01<00:00, 88.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 6313, 'tn': 0, 'fp': 6285, 'fn': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-10-31] Epoch 003 Acc: 0.5027 Loss: 0.69315184: 100%|██████████| 886/886 [00:20<00:00, 44.17it/s]\n",
      "[30-01-2024 22-10-32] Epoch 003 Val. Acc: 0.4988 Val. Loss: 0.69316351: 100%|██████████| 99/99 [00:01<00:00, 81.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 0, 'tn': 6285, 'fp': 0, 'fn': 6313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-10-53] Epoch 004 Acc: 0.5038 Loss: 0.69315965: 100%|██████████| 886/886 [00:20<00:00, 44.30it/s]\n",
      "[30-01-2024 22-10-54] Epoch 004 Val. Acc: 0.4988 Val. Loss: 0.69322550: 100%|██████████| 99/99 [00:01<00:00, 83.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 0, 'tn': 6285, 'fp': 0, 'fn': 6313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-11-14] Epoch 005 Acc: 0.5016 Loss: 0.69317379: 100%|██████████| 886/886 [00:19<00:00, 44.38it/s]\n",
      "[30-01-2024 22-11-16] Epoch 005 Val. Acc: 0.4988 Val. Loss: 0.69317452: 100%|██████████| 99/99 [00:01<00:00, 80.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 0, 'tn': 6285, 'fp': 0, 'fn': 6313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-11-36] Epoch 006 Acc: 0.5022 Loss: 0.69315422: 100%|██████████| 886/886 [00:20<00:00, 43.76it/s]\n",
      "[30-01-2024 22-11-38] Epoch 006 Val. Acc: 0.4988 Val. Loss: 0.69316619: 100%|██████████| 99/99 [00:01<00:00, 67.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': 0, 'tn': 6285, 'fp': 0, 'fn': 6313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[30-01-2024 22-11-45] Epoch 007 Acc: 0.4992 Loss: 0.20810759:  30%|███       | 266/886 [00:06<00:15, 41.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     no_update()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished experiment!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(MODEL\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(device, epoch, optimizer, loss_fn, MODEL, data_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m#val_loss, val_acc, _ = validate(device, epoch, optimizer, loss_fn, MODEL, data_val)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     _, _, metrics \u001b[39m=\u001b[39m validate(device, epoch, loss_fn, MODEL, data_test)\n",
      "\u001b[1;32m/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Adjust learning weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msum(torch\u001b[39m.\u001b[39;49margmax(outputs, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49meq(y))\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m qt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luizp/projects/pibit/src/deep/kddAlexnetTabular.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Gather data and report\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    no_update()\n",
    "    print(\"Finished experiment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
